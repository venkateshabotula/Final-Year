{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tjaqi_plICYq"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import traceback\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Google Drive or local files\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')  # Mount Google Drive\n",
        "\n",
        "# Replace with the path to your dataset\n",
        "dataset_path = '/content/water_availability_data.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Shape:\", data.shape)\n",
        "print(\"Dataset Preview:\\n\", data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxEXifS1IERY",
        "outputId": "20547125-42e5-4db0-9dd3-e579d9c1cc46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (1980, 9)\n",
            "Dataset Preview:\n",
            "         res_state res_district              res_name  res_year res_month  \\\n",
            "0  Andhra Pradesh       Guntur  Dr.KLRS Pulichintala      2009   january   \n",
            "1  Andhra Pradesh       Guntur  Dr.KLRS Pulichintala      2009  february   \n",
            "2  Andhra Pradesh       Guntur  Dr.KLRS Pulichintala      2009     march   \n",
            "3  Andhra Pradesh       Guntur  Dr.KLRS Pulichintala      2009     april   \n",
            "4  Andhra Pradesh       Guntur  Dr.KLRS Pulichintala      2009       may   \n",
            "\n",
            "   res_level  cur_livsto rain_month  rainfall  \n",
            "0  54.895806    0.251452    january       0.0  \n",
            "1  54.095000    0.198107   february       0.0  \n",
            "2  52.902258    0.136903      march       0.3  \n",
            "3  50.533333    0.064367      april       0.0  \n",
            "4  47.592581    0.018258        may       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical and numeric columns\n",
        "categorical_cols = ['res_district', 'res_name', 'res_month', 'rain_month']\n",
        "numeric_cols = ['res_year', 'res_level', 'cur_livsto', 'rainfall']\n",
        "\n",
        "# Drop missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Scale numeric features\n",
        "scaler_X = MinMaxScaler()\n",
        "X = data[numeric_cols]\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "y = data[\"cur_livsto\"].values.reshape(-1, 1)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "def create_lstm_data(X, y, time_steps=1):\n",
        "    X_lstm, y_lstm = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_lstm.append(X[i:i+time_steps])\n",
        "        y_lstm.append(y[i+time_steps])\n",
        "    return np.array(X_lstm), np.array(y_lstm)\n",
        "\n",
        "time_steps = 3\n",
        "X_lstm, y_lstm = create_lstm_data(X_scaled, y_scaled, time_steps)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "uhvEfOvAIeWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42417cc1-ba68-4516-b9d9-f3d104aa01d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b3e672780096>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = le.fit_transform(data[col])\n",
            "<ipython-input-3-b3e672780096>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = le.fit_transform(data[col])\n",
            "<ipython-input-3-b3e672780096>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = le.fit_transform(data[col])\n",
            "<ipython-input-3-b3e672780096>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[col] = le.fit_transform(data[col])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=25, batch_size=32, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEohlfFCIgwa",
        "outputId": "04eac86a-970e-40d0-b383-e1fe811a8727"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0285\n",
            "Epoch 2/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0148\n",
            "Epoch 3/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0101\n",
            "Epoch 4/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093\n",
            "Epoch 5/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077\n",
            "Epoch 6/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0085\n",
            "Epoch 7/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0093\n",
            "Epoch 8/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082\n",
            "Epoch 9/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100\n",
            "Epoch 10/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081\n",
            "Epoch 11/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075\n",
            "Epoch 12/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061\n",
            "Epoch 13/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061\n",
            "Epoch 14/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059\n",
            "Epoch 15/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071\n",
            "Epoch 16/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064\n",
            "Epoch 17/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058\n",
            "Epoch 18/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041\n",
            "Epoch 19/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041\n",
            "Epoch 20/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042\n",
            "Epoch 21/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041\n",
            "Epoch 22/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055\n",
            "Epoch 23/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046\n",
            "Epoch 24/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027\n",
            "Epoch 25/25\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78f27c957d10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('lstm_water_availability_model.h5')\n",
        "\n",
        "# Save encoders and scalers\n",
        "import pickle\n",
        "\n",
        "with open('label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "\n",
        "with open('scalers.pkl', 'wb') as f:\n",
        "    pickle.dump({'scaler_X': scaler_X, 'scaler_y': scaler_y}, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQh1aintIjhX",
        "outputId": "2472b1df-1137-40da-b32c-4fc622b8b415"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('lstm_water_availability_model.h5')\n",
        "\n",
        "# Load encoders and scalers\n",
        "with open('label_encoders.pkl', 'rb') as f:\n",
        "    label_encoders = pickle.load(f)\n",
        "\n",
        "with open('scalers.pkl', 'rb') as f:\n",
        "    scalers = pickle.load(f)\n",
        "scaler_X, scaler_y = scalers['scaler_X'], scalers['scaler_y']\n",
        "\n",
        "# Perform inference\n",
        "def perform_inference(year, district, name, month, rainfall):\n",
        "    try:\n",
        "        # Encode inputs\n",
        "        encoded_district = label_encoders['res_district'].transform([district])[0]\n",
        "        encoded_name = label_encoders['res_name'].transform([name])[0]\n",
        "        encoded_month = label_encoders['res_month'].transform([month])[0]\n",
        "\n",
        "        # Prepare input data\n",
        "        input_data = np.array([[year, rainfall, encoded_district, encoded_month]])\n",
        "        input_scaled = scaler_X.transform(input_data)\n",
        "        input_scaled = input_scaled.reshape((1, 1, input_scaled.shape[1]))\n",
        "\n",
        "        # Make prediction\n",
        "        predicted_scaled = model.predict(input_scaled)\n",
        "        predicted_actual = scaler_y.inverse_transform(predicted_scaled)\n",
        "\n",
        "        return float(predicted_actual[0][0])\n",
        "    except Exception as e:\n",
        "        print(\"Error during inference:\", e)\n",
        "        print(traceback.format_exc())\n",
        "\n",
        "# Example inference\n",
        "year = 2025\n",
        "district = \"Nellore\"  # Replace with an actual district name\n",
        "name = \"Nellore Anicut\"    # Replace with an actual reservoir name\n",
        "month = \"july\"               # Replace with an actual month\n",
        "rainfall = 435.6               # Replace with actual rainfall value\n",
        "\n",
        "predicted_availability = perform_inference(year, district, name, month, rainfall)\n",
        "print(\"Predicted Water Availability:\", predicted_availability)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCtqJhbVIm4y",
        "outputId": "c5bed06a-47d8-43e8-a8de-31627ad34c55"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "Predicted Water Availability: 1.387837290763855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Inverse transform the predictions and actual values to original scale\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_actual = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_actual, y_pred)\n",
        "mae = mean_absolute_error(y_actual, y_pred)\n",
        "\n",
        "print(\"Model Performance on Test Set:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "\n",
        "# Optional: Compute R-squared score\n",
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_actual, y_pred)\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI_-es-nKSfG",
        "outputId": "47779e26-0845-4926-d585-82c6b4c570c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
            "Model Performance on Test Set:\n",
            "Mean Squared Error (MSE): 0.0003\n",
            "Mean Absolute Error (MAE): 0.0075\n",
            "R-squared Score: 0.9001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKsNudALQeOL"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}